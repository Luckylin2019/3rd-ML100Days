{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "### 請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l1\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units = 10, num_neurons = [512, 256, 128], l1_ratio=1e-4, drop_ratio = 0.3):\n",
    "    \n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = BatchNormalization()(input_layer)\n",
    "            x = keras.layers.Dense(units = n_units,\n",
    "                                   activation = 'relu',\n",
    "                                   name = 'hidden_layer'+str(i+1),\n",
    "                                   kernel_regularizer = l1(l1_ratio))(x)\n",
    "            x = Dropout(drop_ratio)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = keras.layers.Dense(units = n_units, \n",
    "                                   activation = 'relu',\n",
    "                                   name = 'hidden_layer'+str(i+1), \n",
    "                                   kernel_regularizer = l1(l1_ratio))(x)\n",
    "            x = Dropout(drop_ratio)(x)\n",
    "    output_layer = keras.layers.Dense(units = output_units, activation = \"softmax\", name = \"output\")(x)\n",
    "    model = keras.models.Model(inputs = [input_layer], outputs = [output_layer])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "MOMENTUM = 0.95\n",
    "L1_EXP = [1e-2, 1e-4, 1e-8, 1e-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Experiment with Regulizer:0.0100000000000\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,754,250\n",
      "Trainable params: 1,746,570\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucky\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 361.0903 - acc: 0.1634 - val_loss: 298.8606 - val_acc: 0.3099\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 237.4103 - acc: 0.2587 - val_loss: 177.2617 - val_acc: 0.3260\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 131.4372 - acc: 0.3074 - val_loss: 89.9178 - val_acc: 0.2387\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 62.5342 - acc: 0.3400 - val_loss: 41.2520 - val_acc: 0.1185\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 32.0081 - acc: 0.3329 - val_loss: 26.2277 - val_acc: 0.1006\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 21.5883 - acc: 0.3072 - val_loss: 18.0901 - val_acc: 0.1031\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 14.6216 - acc: 0.3134 - val_loss: 12.0943 - val_acc: 0.1076\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 9.4958 - acc: 0.3182 - val_loss: 7.7846 - val_acc: 0.1025\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 6.0210 - acc: 0.3130 - val_loss: 5.1319 - val_acc: 0.1026\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 4.2326 - acc: 0.3029 - val_loss: 3.9143 - val_acc: 0.2316\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 3.3858 - acc: 0.2971 - val_loss: 3.2546 - val_acc: 0.2864\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 2.9059 - acc: 0.2950 - val_loss: 2.8726 - val_acc: 0.2704\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 2.6626 - acc: 0.2767 - val_loss: 2.6748 - val_acc: 0.2789\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 2.5483 - acc: 0.2695 - val_loss: 2.5839 - val_acc: 0.2942\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.5133 - acc: 0.2538 - val_loss: 2.5246 - val_acc: 0.2994\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 2.4883 - acc: 0.2520 - val_loss: 2.4817 - val_acc: 0.2945\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 189us/step - loss: 2.4741 - acc: 0.2529 - val_loss: 2.4575 - val_acc: 0.2874\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 2.4619 - acc: 0.2534 - val_loss: 2.4585 - val_acc: 0.2811\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.4533 - acc: 0.2533 - val_loss: 2.4329 - val_acc: 0.2786\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 2.4560 - acc: 0.2539 - val_loss: 2.4288 - val_acc: 0.2839\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 2.4453 - acc: 0.2527 - val_loss: 2.4103 - val_acc: 0.2776\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.4379 - acc: 0.2540 - val_loss: 2.4317 - val_acc: 0.2733\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 2.4340 - acc: 0.2518 - val_loss: 2.4100 - val_acc: 0.2871\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.4315 - acc: 0.2554 - val_loss: 2.3985 - val_acc: 0.2771\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.4306 - acc: 0.2536 - val_loss: 2.3905 - val_acc: 0.2856\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 2.4238 - acc: 0.2557 - val_loss: 2.4111 - val_acc: 0.2633\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 2.4258 - acc: 0.2511 - val_loss: 2.4015 - val_acc: 0.2862\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 2.4160 - acc: 0.2540 - val_loss: 2.3770 - val_acc: 0.2908\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.4191 - acc: 0.2524 - val_loss: 2.3646 - val_acc: 0.2929\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.4172 - acc: 0.2546 - val_loss: 2.3787 - val_acc: 0.2808\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.4111 - acc: 0.2559 - val_loss: 2.3827 - val_acc: 0.2743\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 2.4089 - acc: 0.2577 - val_loss: 2.3941 - val_acc: 0.2862\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 2.4076 - acc: 0.2574 - val_loss: 2.3736 - val_acc: 0.2914\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 2.4011 - acc: 0.2548 - val_loss: 2.3562 - val_acc: 0.2943\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.4014 - acc: 0.2530 - val_loss: 2.3590 - val_acc: 0.2980\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.4004 - acc: 0.2572 - val_loss: 2.3587 - val_acc: 0.30162s - loss: 2.4020\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.4007 - acc: 0.2556 - val_loss: 2.3504 - val_acc: 0.3042\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.4180 - acc: 0.2551 - val_loss: 2.3957 - val_acc: 0.2782\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.4163 - acc: 0.2524 - val_loss: 2.3754 - val_acc: 0.2900\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 2.3958 - acc: 0.2550 - val_loss: 2.3731 - val_acc: 0.2912\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 2.4011 - acc: 0.2557 - val_loss: 2.3931 - val_acc: 0.2955\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.3991 - acc: 0.2549 - val_loss: 2.3457 - val_acc: 0.3028\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 2.3963 - acc: 0.2557 - val_loss: 2.3783 - val_acc: 0.2781\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 2.3946 - acc: 0.2574 - val_loss: 2.3876 - val_acc: 0.2636\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.3989 - acc: 0.2566 - val_loss: 2.3345 - val_acc: 0.3056\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.3874 - acc: 0.2604 - val_loss: 2.3542 - val_acc: 0.2937 2.3900 - acc\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.3936 - acc: 0.2583 - val_loss: 2.3801 - val_acc: 0.2763\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.3898 - acc: 0.2579 - val_loss: 2.3240 - val_acc: 0.3073\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 2.3877 - acc: 0.2591 - val_loss: 2.3251 - val_acc: 0.3028\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.3888 - acc: 0.2626 - val_loss: 2.3591 - val_acc: 0.2835\n",
      "Experiment with Regulizer:0.0001000000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,754,250\n",
      "Trainable params: 1,746,570\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 6.5988 - acc: 0.1609 - val_loss: 5.9619 - val_acc: 0.3062\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 6.2011 - acc: 0.2431 - val_loss: 5.7984 - val_acc: 0.3576\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 6.0537 - acc: 0.2774 - val_loss: 5.7178 - val_acc: 0.3777\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 5.9474 - acc: 0.3024 - val_loss: 5.6609 - val_acc: 0.3919\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 5.8759 - acc: 0.3142 - val_loss: 5.6106 - val_acc: 0.4037\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 5.8126 - acc: 0.3266 - val_loss: 5.5695 - val_acc: 0.4097\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 5.7625 - acc: 0.3385 - val_loss: 5.5313 - val_acc: 0.4191\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 5.7110 - acc: 0.3477 - val_loss: 5.4946 - val_acc: 0.4275\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 5.6677 - acc: 0.3560 - val_loss: 5.4646 - val_acc: 0.4310\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 5.6215 - acc: 0.3668 - val_loss: 5.4325 - val_acc: 0.4360\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 5.5918 - acc: 0.3695 - val_loss: 5.4039 - val_acc: 0.4404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 5.5499 - acc: 0.3780 - val_loss: 5.3733 - val_acc: 0.4432\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 5.5188 - acc: 0.3844 - val_loss: 5.3481 - val_acc: 0.4442\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 5.4829 - acc: 0.3908 - val_loss: 5.3198 - val_acc: 0.4483\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 5.4489 - acc: 0.3980 - val_loss: 5.2933 - val_acc: 0.4534\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 5.4224 - acc: 0.3986 - val_loss: 5.2683 - val_acc: 0.4527\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 5.3906 - acc: 0.4030 - val_loss: 5.2434 - val_acc: 0.4566\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 5.3627 - acc: 0.4080 - val_loss: 5.2189 - val_acc: 0.4569\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 5.3372 - acc: 0.4078 - val_loss: 5.1951 - val_acc: 0.4606\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 5.3035 - acc: 0.4155 - val_loss: 5.1701 - val_acc: 0.4644\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 5.2838 - acc: 0.4183 - val_loss: 5.1483 - val_acc: 0.4636\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 5.2600 - acc: 0.4224 - val_loss: 5.1241 - val_acc: 0.4666\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 5.2284 - acc: 0.4276 - val_loss: 5.1002 - val_acc: 0.4709\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 5.2082 - acc: 0.4273 - val_loss: 5.0795 - val_acc: 0.4735\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 5.1793 - acc: 0.4329 - val_loss: 5.0563 - val_acc: 0.4748\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 5.1512 - acc: 0.4383 - val_loss: 5.0348 - val_acc: 0.4771\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 5.1262 - acc: 0.4396 - val_loss: 5.0128 - val_acc: 0.4805\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 5.1103 - acc: 0.4419 - val_loss: 4.9933 - val_acc: 0.4814\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 5.0864 - acc: 0.4430 - val_loss: 4.9707 - val_acc: 0.4797\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 5.0596 - acc: 0.4464 - val_loss: 4.9485 - val_acc: 0.4825\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 5.0380 - acc: 0.4480 - val_loss: 4.9273 - val_acc: 0.4866\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 5.0146 - acc: 0.4514 - val_loss: 4.9078 - val_acc: 0.4868\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 4.9934 - acc: 0.4529 - val_loss: 4.8871 - val_acc: 0.4883\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 4.9682 - acc: 0.4548 - val_loss: 4.8673 - val_acc: 0.4882\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 4.9465 - acc: 0.4582 - val_loss: 4.8485 - val_acc: 0.4882\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 4.9291 - acc: 0.4592 - val_loss: 4.8283 - val_acc: 0.4925\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 4.9014 - acc: 0.4648 - val_loss: 4.8077 - val_acc: 0.4934\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 4.8809 - acc: 0.4635 - val_loss: 4.7866 - val_acc: 0.4956\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 4.8596 - acc: 0.4669 - val_loss: 4.7689 - val_acc: 0.4971\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 4.8404 - acc: 0.4670 - val_loss: 4.7486 - val_acc: 0.4989\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 4.8166 - acc: 0.4718 - val_loss: 4.7301 - val_acc: 0.5008\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 4.7991 - acc: 0.4717 - val_loss: 4.7087 - val_acc: 0.5025oss: 4.79\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 4.7754 - acc: 0.4727 - val_loss: 4.6927 - val_acc: 0.5028\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 4.7539 - acc: 0.4765 - val_loss: 4.6719 - val_acc: 0.5067\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 4.7347 - acc: 0.4757 - val_loss: 4.6522 - val_acc: 0.5057\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 4.7139 - acc: 0.4809 - val_loss: 4.6345 - val_acc: 0.5056\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 4.6933 - acc: 0.4814 - val_loss: 4.6157 - val_acc: 0.5088\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 4.6745 - acc: 0.4841 - val_loss: 4.5982 - val_acc: 0.5103\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 4.6545 - acc: 0.4858 - val_loss: 4.5781 - val_acc: 0.5122\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 4.6314 - acc: 0.4886 - val_loss: 4.5591 - val_acc: 0.5142\n",
      "Experiment with Regulizer:0.0000000100000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,754,250\n",
      "Trainable params: 1,746,570\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 2.6202 - acc: 0.1609 - val_loss: 1.9846 - val_acc: 0.3002\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 2.2563 - acc: 0.2427 - val_loss: 1.8330 - val_acc: 0.3524\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 2.1019 - acc: 0.2801 - val_loss: 1.7596 - val_acc: 0.3788\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 2.0226 - acc: 0.3001 - val_loss: 1.7180 - val_acc: 0.3907\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 1.9624 - acc: 0.3152 - val_loss: 1.6828 - val_acc: 0.4064\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 1.9102 - acc: 0.3285 - val_loss: 1.6558 - val_acc: 0.4120\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 10s 194us/step - loss: 1.8793 - acc: 0.3367 - val_loss: 1.6321 - val_acc: 0.4192\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 1.8472 - acc: 0.3474 - val_loss: 1.6108 - val_acc: 0.4272\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.8196 - acc: 0.3550 - val_loss: 1.5968 - val_acc: 0.4352\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 1.7893 - acc: 0.3653 - val_loss: 1.5815 - val_acc: 0.4408\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.7707 - acc: 0.3710 - val_loss: 1.5674 - val_acc: 0.4443\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.7515 - acc: 0.3752 - val_loss: 1.5564 - val_acc: 0.4461\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 1.7317 - acc: 0.3812 - val_loss: 1.5448 - val_acc: 0.4504\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.7108 - acc: 0.3909 - val_loss: 1.5353 - val_acc: 0.4548\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 1.7044 - acc: 0.3914 - val_loss: 1.5251 - val_acc: 0.4591\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.6865 - acc: 0.3993 - val_loss: 1.5174 - val_acc: 0.4593\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 1.6728 - acc: 0.4010 - val_loss: 1.5097 - val_acc: 0.4601\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 1.6570 - acc: 0.4072 - val_loss: 1.5009 - val_acc: 0.4640\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 1.6543 - acc: 0.4071 - val_loss: 1.4935 - val_acc: 0.4659\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.6375 - acc: 0.4126 - val_loss: 1.4862 - val_acc: 0.4681\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 1.6310 - acc: 0.4162 - val_loss: 1.4811 - val_acc: 0.4696\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 1.6260 - acc: 0.4203 - val_loss: 1.4746 - val_acc: 0.4712\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 1.6155 - acc: 0.4232 - val_loss: 1.4689 - val_acc: 0.4728\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.6028 - acc: 0.4259 - val_loss: 1.4635 - val_acc: 0.4739\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.6003 - acc: 0.4272 - val_loss: 1.4582 - val_acc: 0.4769\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.5848 - acc: 0.4313 - val_loss: 1.4512 - val_acc: 0.4795\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.5732 - acc: 0.4330 - val_loss: 1.4483 - val_acc: 0.4795\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 1.5699 - acc: 0.4370 - val_loss: 1.4427 - val_acc: 0.4820\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.5671 - acc: 0.4379 - val_loss: 1.4381 - val_acc: 0.4831\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 1.5579 - acc: 0.4435 - val_loss: 1.4335 - val_acc: 0.4846\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 1.5551 - acc: 0.4424 - val_loss: 1.4294 - val_acc: 0.4868\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.5469 - acc: 0.4477 - val_loss: 1.4254 - val_acc: 0.4870\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.5414 - acc: 0.4507 - val_loss: 1.4223 - val_acc: 0.4887\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.5320 - acc: 0.4490 - val_loss: 1.4173 - val_acc: 0.4927\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.5275 - acc: 0.4554 - val_loss: 1.4128 - val_acc: 0.4933\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 1.5230 - acc: 0.4527 - val_loss: 1.4090 - val_acc: 0.4927 3s - loss: 1.529\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 1.5190 - acc: 0.4558 - val_loss: 1.4053 - val_acc: 0.4964\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 1.5111 - acc: 0.4588 - val_loss: 1.4020 - val_acc: 0.4970\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 1.5041 - acc: 0.4618 - val_loss: 1.3981 - val_acc: 0.4986\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.5038 - acc: 0.4611 - val_loss: 1.3946 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.4927 - acc: 0.4680 - val_loss: 1.3913 - val_acc: 0.4990\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.4940 - acc: 0.4637 - val_loss: 1.3883 - val_acc: 0.5012\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 1.4851 - acc: 0.4705 - val_loss: 1.3847 - val_acc: 0.5033\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.4840 - acc: 0.4690 - val_loss: 1.3819 - val_acc: 0.5038\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 1.4770 - acc: 0.4722 - val_loss: 1.3789 - val_acc: 0.5051\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.4710 - acc: 0.4719 - val_loss: 1.3760 - val_acc: 0.5081\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.4675 - acc: 0.4739 - val_loss: 1.3733 - val_acc: 0.5077\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 1.4649 - acc: 0.4743 - val_loss: 1.3695 - val_acc: 0.5106\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.4522 - acc: 0.4792 - val_loss: 1.3687 - val_acc: 0.5102\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 1.4518 - acc: 0.4801 - val_loss: 1.3661 - val_acc: 0.5100\n",
      "Experiment with Regulizer:0.0000000000010\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,754,250\n",
      "Trainable params: 1,746,570\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 12s 238us/step - loss: 2.6371 - acc: 0.1460 - val_loss: 1.9962 - val_acc: 0.2955\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 10s 202us/step - loss: 2.2309 - acc: 0.2379 - val_loss: 1.8490 - val_acc: 0.3464\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 2.1000 - acc: 0.2720 - val_loss: 1.7753 - val_acc: 0.3746\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 2.0176 - acc: 0.2933 - val_loss: 1.7308 - val_acc: 0.3943\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.9625 - acc: 0.3113 - val_loss: 1.6996 - val_acc: 0.4009\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.9179 - acc: 0.3190 - val_loss: 1.6719 - val_acc: 0.4138\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.8731 - acc: 0.3355 - val_loss: 1.6491 - val_acc: 0.4207\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.8516 - acc: 0.3393 - val_loss: 1.6318 - val_acc: 0.4258\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 1.8245 - acc: 0.3511 - val_loss: 1.6144 - val_acc: 0.4322\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.7947 - acc: 0.3615 - val_loss: 1.6003 - val_acc: 0.4348\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.7729 - acc: 0.3636 - val_loss: 1.5867 - val_acc: 0.4415\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.7589 - acc: 0.3707 - val_loss: 1.5748 - val_acc: 0.4445\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 1.7372 - acc: 0.3774 - val_loss: 1.5627 - val_acc: 0.4483\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 1.7225 - acc: 0.3826 - val_loss: 1.5515 - val_acc: 0.4507\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.7096 - acc: 0.3862 - val_loss: 1.5414 - val_acc: 0.4531\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.6949 - acc: 0.3903 - val_loss: 1.5325 - val_acc: 0.4554\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.6786 - acc: 0.3975 - val_loss: 1.5231 - val_acc: 0.4593\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.6670 - acc: 0.4009 - val_loss: 1.5149 - val_acc: 0.4617\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.6607 - acc: 0.4045 - val_loss: 1.5082 - val_acc: 0.4658\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 1.6508 - acc: 0.4069 - val_loss: 1.5016 - val_acc: 0.4698\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.6338 - acc: 0.4139 - val_loss: 1.4948 - val_acc: 0.4698\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.6269 - acc: 0.4143 - val_loss: 1.4886 - val_acc: 0.4731\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.6165 - acc: 0.4184 - val_loss: 1.4818 - val_acc: 0.4740\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 1.6080 - acc: 0.4246 - val_loss: 1.4756 - val_acc: 0.4760\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.6018 - acc: 0.4237 - val_loss: 1.4702 - val_acc: 0.4767\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.5960 - acc: 0.4266 - val_loss: 1.4649 - val_acc: 0.4778\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 1.5837 - acc: 0.4327 - val_loss: 1.4587 - val_acc: 0.4827\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.5752 - acc: 0.4352 - val_loss: 1.4546 - val_acc: 0.4837\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.5716 - acc: 0.4361 - val_loss: 1.4493 - val_acc: 0.4846\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.5649 - acc: 0.4390 - val_loss: 1.4452 - val_acc: 0.4858\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 1.5562 - acc: 0.4410 - val_loss: 1.4408 - val_acc: 0.4891\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.5486 - acc: 0.4459 - val_loss: 1.4364 - val_acc: 0.4894\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.5433 - acc: 0.4472 - val_loss: 1.4321 - val_acc: 0.4906\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.5382 - acc: 0.4492 - val_loss: 1.4275 - val_acc: 0.4905\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 1.5338 - acc: 0.4490 - val_loss: 1.4238 - val_acc: 0.4923\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.5210 - acc: 0.4544 - val_loss: 1.4192 - val_acc: 0.4944\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 1.5198 - acc: 0.4558 - val_loss: 1.4164 - val_acc: 0.4930\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.5150 - acc: 0.4549 - val_loss: 1.4141 - val_acc: 0.4924\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 1.5138 - acc: 0.4561 - val_loss: 1.4106 - val_acc: 0.4952\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.5058 - acc: 0.4590 - val_loss: 1.4062 - val_acc: 0.4961\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.4966 - acc: 0.4616 - val_loss: 1.4043 - val_acc: 0.4976\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.4897 - acc: 0.4650 - val_loss: 1.4004 - val_acc: 0.4988\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 1.4867 - acc: 0.4666 - val_loss: 1.3974 - val_acc: 0.5005\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 1.4842 - acc: 0.4680 - val_loss: 1.3948 - val_acc: 0.5007\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.4813 - acc: 0.4690 - val_loss: 1.3907 - val_acc: 0.5039\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.4770 - acc: 0.4676 - val_loss: 1.3889 - val_acc: 0.5041\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.4672 - acc: 0.4728 - val_loss: 1.3842 - val_acc: 0.5052\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 1.4665 - acc: 0.4706 - val_loss: 1.3823 - val_acc: 0.5051\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 1.4639 - acc: 0.4739 - val_loss: 1.3793 - val_acc: 0.5056\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 1.4616 - acc: 0.4756 - val_loss: 1.3752 - val_acc: 0.5063\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "for regulizer_ratio in L1_EXP:\n",
    "    keras.backend.clear_session()\n",
    "    print('Experiment with Regulizer:{:.13f}'.format(regulizer_ratio))\n",
    "    model = build_mlp(input_shape = x_train.shape[1:], l1_ratio = regulizer_ratio)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr = LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = optimizer)\n",
    "    \n",
    "    model.fit(x_train, y_train, batch_size = BATCH_SIZE, \n",
    "              epochs = EPOCHS, validation_data = (x_test, y_test), \n",
    "              shuffle = True)\n",
    "    \n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-l1-%s\" % str(regulizer_ratio)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "color_bar = ['r', 'g', 'b', 'k', 'y', 'm']\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
